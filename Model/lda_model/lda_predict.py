import numpy as np
from joblib import load
from sklearn.feature_extraction.text import TfidfVectorizer
import sys

def load_model_and_tools(model_path, vectorizer_path, pca_path):
    lda_model = load(model_path)
    vectorizer = load(vectorizer_path)
    pca = load(pca_path)
    print("M√¥ h√¨nh v√† c√¥ng c·ª• ƒë√£ ƒë∆∞·ª£c t·∫£i th√†nh c√¥ng.")
    return lda_model, vectorizer, pca

def predict_url(url, lda_model, vectorizer, pca):
    url_tfidf = vectorizer.transform([url])
    url_pca = pca.transform(url_tfidf.toarray())
    prob = lda_model.predict_proba(url_pca)[:, 1][0]
    label = lda_model.predict(url_pca)[0]
    return label, prob


model_path = 'lda_model_crawl_data.joblib'
vectorizer_path = 'tfidf_vectorizer_crawl_data.joblib'
pca_path = 'pca_model_crawl_data.joblib'
lda_model, vectorizer, pca = load_model_and_tools(model_path, vectorizer_path, pca_path)


while True:
    print("\nNh·∫≠p URL ƒë·ªÉ ph√¢n lo·∫°i (ho·∫∑c nh·∫≠p 'exit' ƒë·ªÉ tho√°t):")
    user_input = input("URL: ").strip()
    if user_input.lower() == 'exit':
        print("ƒê√£ tho√°t ch∆∞∆°ng tr√¨nh.")
        sys.exit()
    elif user_input:
        try:
            label, prob = predict_url(user_input, lda_model, vectorizer, pca)
            if label == 0:
                print(f"üî¥ URL ƒë∆∞·ª£c ph√¢n lo·∫°i l√† **Gi·∫£ m·∫°o** v·ªõi x√°c su·∫•t {(1 - prob) * 100:.2f}%.")
            else:
                print(f"üü¢ URL ƒë∆∞·ª£c ph√¢n lo·∫°i l√† **An to√†n** v·ªõi x√°c su·∫•t {prob * 100:.2f}%.")
        except Exception as e:
            print(f"ƒê√£ x·∫£y ra l·ªói khi ph√¢n lo·∫°i: {e}")
    else:
        print("Vui l√≤ng nh·∫≠p m·ªôt URL h·ª£p l·ªá.")
